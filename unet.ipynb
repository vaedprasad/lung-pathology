{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liZSfDQlfe9e",
        "outputId": "ed7eadcb-99f4-4b81-843f-24516319bfce"
      },
      "source": [
        "!pip install pytorch-lightning\n",
        "!pip install wandb\n",
        "!pip install -U git+https://github.com/qubvel/segmentation_models.pytorch\n",
        "#!pip install lightning-bolts\n",
        "#!pip install torchmetrics"
      ],
      "id": "liZSfDQlfe9e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/a1/a991780873b5fd760fb99dfda01916fe9e5b186f0ba70a120e6b4f79cfaa/pytorch_lightning-1.3.1-py3-none-any.whl (805kB)\n",
            "\u001b[K     |████████████████████████████████| 808kB 24.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
            "Collecting torchmetrics>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/e8/513cd9d0b1c83dc14cd8f788d05cd6a34758d4fd7e4f9e5ecd5d7d599c95/torchmetrics-0.3.2-py3-none-any.whl (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 33.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.41.1)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 29.5MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/14/52/aa227a0884df71ed1957649085adf2b8bc2a1816d037c2f18b3078854516/pyDeprecate-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.4.1)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.8.1+cu101)\n",
            "Collecting fsspec[http]>=2021.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 56.4MB/s \n",
            "\u001b[?25hCollecting PyYAML<=5.4.1,>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 43.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-lightning) (2.4.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.30.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.12.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.32.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.3.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.12.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (56.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning) (3.7.4.3)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 38.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch-lightning) (21.2.0)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 57.4MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 53.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.4.1)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=6a41f8cf278ad38fa01827b692aefe0a4b3b92dee3ca774b495e453b9097656b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built future\n",
            "Installing collected packages: torchmetrics, future, pyDeprecate, async-timeout, multidict, yarl, aiohttp, fsspec, PyYAML, pytorch-lightning\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.4.0 future-0.18.2 multidict-5.1.0 pyDeprecate-0.3.0 pytorch-lightning-1.3.1 torchmetrics-0.3.2 yarl-1.6.3\n",
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/5f/45439b4767334b868e1c8c35b1b0ba3747d8c21be77b79f09eed7aa3c72b/wandb-0.10.30-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 27.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.1)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/da/6f6224fdfc47dab57881fe20c0d1bc3122be290198ba0bf26a953a045d92/GitPython-3.1.17-py3-none-any.whl (166kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 50.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 14.0MB/s \n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/4a/a54b254f67d8f4052338d54ebe90126f200693440a93ef76d254d581e3ec/sentry_sdk-1.1.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 36.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.1.0)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pathtools, subprocess32\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=f3cd1796246cf8cb03075f43d693ab79f383917d2c64eef9b7497211b425cd2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=eeff8274b9932858ffc7a6d69118931969139d3d37a492ad28c214acf3498bf4\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built pathtools subprocess32\n",
            "Installing collected packages: smmap, gitdb, GitPython, docker-pycreds, configparser, pathtools, subprocess32, shortuuid, sentry-sdk, wandb\n",
            "Successfully installed GitPython-3.1.17 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.1.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.30\n",
            "Collecting git+https://github.com/qubvel/segmentation_models.pytorch\n",
            "  Cloning https://github.com/qubvel/segmentation_models.pytorch to /tmp/pip-req-build-5vwvn2so\n",
            "  Running command git clone -q https://github.com/qubvel/segmentation_models.pytorch /tmp/pip-req-build-5vwvn2so\n",
            "Requirement already satisfied, skipping upgrade: torchvision>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch==0.1.3) (0.9.1+cu101)\n",
            "Collecting pretrainedmodels==0.7.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.5MB/s \n",
            "\u001b[?25hCollecting efficientnet-pytorch==0.6.3\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n",
            "Collecting timm==0.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/2d/39ecc56fbb202e1891c317e8e44667299bc3b0762ea2ed6aaaa2c2f6613c/timm-0.3.2-py3-none-any.whl (244kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation-models-pytorch==0.1.3) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation-models-pytorch==0.1.3) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation-models-pytorch==0.1.3) (1.8.1+cu101)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.1.3) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision>=0.3.0->segmentation-models-pytorch==0.1.3) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch==0.1.3) (1.15.0)\n",
            "Building wheels for collected packages: segmentation-models-pytorch, pretrainedmodels, efficientnet-pytorch\n",
            "  Building wheel for segmentation-models-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segmentation-models-pytorch: filename=segmentation_models_pytorch-0.1.3-cp37-none-any.whl size=83164 sha256=a4f4e159d4463d33aa41a71fc4d26237014bd0c42a5b5029ca55b4ffe13da113\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m76b6go0/wheels/79/3f/09/1587a252e0314d26ad242d6d2e165622ab95c95e5cfe4b942c\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp37-none-any.whl size=60963 sha256=fb6fd52e671be9924e171b3b5362d74f4ede7e5dc146473c2c7f2953f90b85cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp37-none-any.whl size=12420 sha256=b6c8f11115eba1145f489a316059c65d0754cee8f14fbd7115cfac1f17dd1c5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n",
            "Successfully built segmentation-models-pytorch pretrainedmodels efficientnet-pytorch\n",
            "Installing collected packages: munch, pretrainedmodels, efficientnet-pytorch, timm, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.6.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.1.3 timm-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "patient-surgeon"
      },
      "source": [
        "import math\n",
        "import os\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import imageio\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "from torch import nn, tensor\n",
        "from torch.distributions.categorical import Categorical\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "import wandb\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.metrics import functional as FM\n",
        "from pytorch_lightning.callbacks import Callback, EarlyStopping\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "import segmentation_models_pytorch as smp"
      ],
      "id": "patient-surgeon",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM0jPI7ofgW4",
        "outputId": "6e43c1b8-f388-4bc6-d622-bb88d11b3697"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "id": "KM0jPI7ofgW4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE20-CkZf214"
      },
      "source": [
        "drive_path = \"/content/drive/MyDrive\"\n",
        "examples_dir = f\"{drive_path}/imc-prediction/examples\"\n",
        "checkpoints_dir = f\"{drive_path}/imc-prediction/checkpoints\""
      ],
      "id": "sE20-CkZf214",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_PINOovfvvC"
      },
      "source": [
        "#n_protein_channels = 38\n",
        "#collagen_index = 21\n",
        "#n_protein_channels = 27\n",
        "#collagen_index = 14\n",
        "n_protein_channels = 3\n",
        "collagen_index = 1"
      ],
      "id": "H_PINOovfvvC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arranged-drama"
      },
      "source": [
        "console_logger = logging.getLogger(\"pytorch_lightning\")\n",
        "console_logger.setLevel(logging.DEBUG)"
      ],
      "id": "arranged-drama",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57bP_s459km4"
      },
      "source": [
        "# adapted from github.com/PyTorchLightning/lightning-bolts/blob/master/pl_bolts/models/vision/unet.py\n",
        "class UNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes,\n",
        "        input_channels=3,\n",
        "        num_layers=5,\n",
        "        features_start=64,\n",
        "        bilinear=False,\n",
        "        dropout=0,\n",
        "    ):\n",
        "        if num_layers < 1:\n",
        "            raise ValueError(f\"num_layers={num_layers}, expected: num_layers > 0\")\n",
        "\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        layers = [DoubleConv(input_channels, features_start, dropout)]\n",
        "\n",
        "        feats = features_start\n",
        "        for _ in range(num_layers - 1):\n",
        "            layers.append(Down(feats, feats * 2, dropout))\n",
        "            feats *= 2\n",
        "\n",
        "        for _ in range(num_layers - 1):\n",
        "            layers.append(Up(feats, feats // 2, dropout, bilinear))\n",
        "            feats //= 2\n",
        "\n",
        "        layers.append(nn.Conv2d(feats, num_classes, kernel_size=1))\n",
        "\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        xi = [self.layers[0](x)]\n",
        "        # Down path\n",
        "        for layer in self.layers[1:self.num_layers]:\n",
        "            xi.append(layer(xi[-1]))\n",
        "        # Up path\n",
        "        for i, layer in enumerate(self.layers[self.num_layers:-1]):\n",
        "            xi[-1] = layer(xi[-1], xi[-2 - i])\n",
        "        return self.layers[-1](xi[-1])\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, dropout=0):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "            #nn.BatchNorm2d(out_ch),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
        "            #nn.BatchNorm2d(out_ch),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, dropout=0):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            DoubleConv(in_ch, out_ch, dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, dropout=0, bilinear=False):\n",
        "        super().__init__()\n",
        "        self.upsample = None\n",
        "        if bilinear:\n",
        "            self.upsample = nn.Sequential(\n",
        "                nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True),\n",
        "                nn.Conv2d(in_ch, in_ch // 2, kernel_size=1),\n",
        "            )\n",
        "        else:\n",
        "            self.upsample = nn.ConvTranspose2d(in_ch, in_ch // 2, kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv = DoubleConv(in_ch, out_ch, dropout)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.upsample(x1)\n",
        "\n",
        "        # pad x1 to the size of x2\n",
        "        diff_h = x2.shape[2] - x1.shape[2]\n",
        "        diff_w = x2.shape[3] - x1.shape[3]\n",
        "\n",
        "        x1 = F.pad(\n",
        "            x1,\n",
        "            [diff_w // 2, diff_w - diff_w // 2, diff_h // 2, diff_h - diff_h // 2],\n",
        "        )\n",
        "\n",
        "        # concatenate along the channels axis\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "        # output one channel for each protein channel and then take loss for each?"
      ],
      "id": "57bP_s459km4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thousand-azerbaijan"
      },
      "source": [
        "class MyUNet(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        #num_features,\n",
        "        #kernel_size,\n",
        "        #stride,\n",
        "        #padding,\n",
        "        batch_size,  # here just for inclusion in wandb hparams\n",
        "        input_channels=1,\n",
        "        num_layers=4,\n",
        "        dropout=0,\n",
        "        learning_rate=3e-5,\n",
        "        weight_decay=0,\n",
        "        #protein_multiplier=1,\n",
        "        #protein_multiplier_index=0,\n",
        "        architecture=\"smp.UnetPlusPlus\",\n",
        "        encoder_name=\"resnet34\",\n",
        "        encoder_depth=5,\n",
        "        decoder_channels=(256, 128, 64, 32, 16),\n",
        "        decoder_use_batchnorm=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        if architecture == \"UNet\":\n",
        "            self.net = UNet(\n",
        "                features_start=64,\n",
        "                input_channels=input_channels,\n",
        "                num_layers=num_layers,\n",
        "                #num_classes=2,\n",
        "                num_classes=n_protein_channels,\n",
        "                dropout=dropout,\n",
        "            )\n",
        "        elif architecture == \"smp.Unet\":\n",
        "            self.net = smp.Unet(\n",
        "                encoder_name=encoder_name,\n",
        "                encoder_depth=encoder_depth,\n",
        "                encoder_weights=\"imagenet\",\n",
        "                decoder_use_batchnorm=decoder_use_batchnorm,\n",
        "                decoder_channels=decoder_channels,\n",
        "                #decoder_attention_type=None,\n",
        "                in_channels=input_channels,\n",
        "                classes=n_protein_channels,\n",
        "                aux_params=dict(\n",
        "                    dropout=dropout,\n",
        "                    classes=n_protein_channels,\n",
        "                ),\n",
        "            )\n",
        "        elif architecture == \"smp.UnetPlusPlus\":\n",
        "            self.net = smp.UnetPlusPlus(\n",
        "                encoder_name=encoder_name,\n",
        "                encoder_depth=encoder_depth,\n",
        "                encoder_weights=\"imagenet\",\n",
        "                decoder_use_batchnorm=decoder_use_batchnorm,\n",
        "                decoder_channels=decoder_channels,\n",
        "                #decoder_attention_type=None,\n",
        "                in_channels=input_channels,\n",
        "                classes=n_protein_channels,\n",
        "                aux_params=dict(\n",
        "                    dropout=dropout,\n",
        "                    classes=n_protein_channels,\n",
        "                ),\n",
        "            )\n",
        "        elif architecture == \"smp.MAnet\":\n",
        "            self.net = smp.MAnet(\n",
        "                encoder_name=encoder_name,\n",
        "                encoder_depth=encoder_depth,\n",
        "                encoder_weights=\"imagenet\",\n",
        "                decoder_use_batchnorm=decoder_use_batchnorm,\n",
        "                decoder_channels=decoder_channels,\n",
        "                #decoder_attention_type=None,\n",
        "                in_channels=input_channels,\n",
        "                classes=n_protein_channels,\n",
        "                aux_params=dict(\n",
        "                    dropout=dropout,\n",
        "                    classes=n_protein_channels,\n",
        "                ),\n",
        "            )\n",
        "        #self.loss_multiplier = torch.ones(n_protein_channels, 1, 1).cuda() / protein_multiplier\n",
        "        #self.loss_multiplier[protein_multiplier_index, 0, 0] = 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        if \"smp.\" in self.hparams.architecture:\n",
        "            return self.net(x[:, :, :-15, :-16])[0]\n",
        "        else:\n",
        "            return self.net(x)\n",
        "        #return self.net(x)[:, 1:]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        if \"smp.\" in self.hparams.architecture:\n",
        "            y = y[:, :, :-15, :-16]\n",
        "        y_pred = self(x)\n",
        "        #loss = F.binary_cross_entropy(torch.sigmoid(y_pred.flatten(0, 1)), y)\n",
        "        #loss = (F.binary_cross_entropy(torch.sigmoid(y_pred), y, reduction=\"none\") * self.loss_multiplier).mean()\n",
        "        loss = F.binary_cross_entropy(torch.sigmoid(y_pred), y)\n",
        "        self.log(\"train_loss\", loss, on_epoch=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        if \"smp.\" in self.hparams.architecture:\n",
        "            y = y[:, :, :-15, :-16]\n",
        "        y_pred = self(x)\n",
        "        #loss = F.binary_cross_entropy(torch.sigmoid(y_pred.flatten(0, 1)), y)\n",
        "        #loss = (F.binary_cross_entropy(torch.sigmoid(y_pred), y, reduction=\"none\") * self.loss_multiplier).mean()\n",
        "        loss = F.binary_cross_entropy(torch.sigmoid(y_pred), y)\n",
        "        loss_collagen = F.binary_cross_entropy(torch.sigmoid(y_pred[:, collagen_index]), y[:, collagen_index])\n",
        "        self.log(\"val_loss\", loss, on_epoch=True, logger=True)\n",
        "        self.log(\"val_loss_collagen\", loss_collagen, on_epoch=True, logger=True)\n",
        "        return {\n",
        "            \"val_loss\": loss,\n",
        "            \"val_loss_collagen\": loss_collagen,\n",
        "        }\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(\n",
        "            self.parameters(),\n",
        "            lr=self.hparams.learning_rate,\n",
        "            weight_decay=self.hparams.weight_decay,\n",
        "        )"
      ],
      "id": "thousand-azerbaijan",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB1fAfJM2zjb"
      },
      "source": [
        "# assumes batch size of 1 currently\n",
        "def display_predictions(loader):#, protein_multiplier_index):\n",
        "    n_rows = 14\n",
        "    n_cols = 8\n",
        "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 1.5, n_rows * 1.5))\n",
        "\n",
        "    for i, (xs, ys) in enumerate(loader):\n",
        "        if i == n_rows:\n",
        "            break\n",
        "\n",
        "        model.eval()\n",
        "        preds = model(xs.cuda()).detach().cpu().numpy()\n",
        "\n",
        "        axs[i][0].imshow(xs[0][1])\n",
        "        axs[i][1].imshow(xs[0][0])\n",
        "        axs[i][2].imshow(ys[0][0])\n",
        "        axs[i][3].imshow(preds[0][0])\n",
        "        axs[i][4].imshow(ys[0][1])\n",
        "        axs[i][5].imshow(preds[0][1])\n",
        "        axs[i][6].imshow(ys[0][2])\n",
        "        axs[i][7].imshow(preds[0][2])\n",
        "\n",
        "        for j in range(n_cols):\n",
        "            axs[i][j].set_xticks([])\n",
        "            axs[i][j].set_yticks([])\n",
        "\n",
        "        fig.tight_layout(pad=0)\n",
        "\n",
        "    axs[0][0].set_title(\"DNA input\")\n",
        "    axs[0][1].set_title(\"Pano input\")\n",
        "    axs[0][2].set_title(\"True alpha\")\n",
        "    axs[0][3].set_title(\"Pred alpha\")\n",
        "    axs[0][4].set_title(\"True collagen\")\n",
        "    axs[0][5].set_title(\"Pred collagen\")\n",
        "    axs[0][6].set_title(\"True keratin\")\n",
        "    axs[0][7].set_title(\"Pred keratin\")\n",
        "    axs[-1][0].set_title(\"DNA input\", y=-0.13)\n",
        "    axs[-1][1].set_title(\"Pano input\", y=-0.13)\n",
        "    axs[-1][2].set_title(\"True alpha\", y=-0.13)\n",
        "    axs[-1][3].set_title(\"Pred alpha\", y=-0.13)\n",
        "    axs[-1][4].set_title(\"True collagen\", y=-0.13)\n",
        "    axs[-1][5].set_title(\"Pred collagen\", y=-0.13)\n",
        "    axs[-1][6].set_title(\"True keratin\", y=-0.13)\n",
        "    axs[-1][7].set_title(\"Pred keratin\", y=-0.13)"
      ],
      "id": "VB1fAfJM2zjb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sensitive-introduction"
      },
      "source": [
        "class LoggingCallback(Callback):\n",
        "    def on_train_epoch_end(self, trainer, pl_module, outputs):\n",
        "        if trainer.current_epoch < 3 or (trainer.current_epoch + 1) % 3 == 0:\n",
        "            display_predictions(train_loader)#, pl_module.hparams.protein_multiplier_index)\n",
        "            trainer.logger.experiment.log(\n",
        "                {\n",
        "                    \"train_preds\": wandb.Image(plt, caption=f\"epoch_{trainer.current_epoch}\"),\n",
        "                    \"global_step\": trainer.global_step,\n",
        "                },\n",
        "                commit=False,  # docs: \"When logging manually ... make sure to use commit=False ...\"\n",
        "            )\n",
        "        if (trainer.current_epoch + 1) % 3 == 0:\n",
        "            trainer.save_checkpoint(f\"epoch_{trainer.current_epoch}.ckpt\")\n",
        "            trainer.logger.experiment.save(f\"epoch_{trainer.current_epoch}.ckpt\")\n",
        "            console_logger.info(f\"Saved epoch_{trainer.current_epoch}.ckpt to wandb server\")\n",
        "\n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        if trainer.current_epoch < 3 or (trainer.current_epoch + 1) % 3 == 0:\n",
        "            display_predictions(val_loader)#, pl_module.hparams.protein_multiplier_index)\n",
        "            trainer.logger.experiment.log(\n",
        "                {\n",
        "                    \"val_preds\": wandb.Image(plt, caption=f\"epoch_{trainer.current_epoch}\"),\n",
        "                    \"global_step\": trainer.global_step,\n",
        "                },\n",
        "                commit=False,  # docs: \"When logging manually ... make sure to use commit=False ...\"\n",
        "            )"
      ],
      "id": "sensitive-introduction",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfZH1qdT2bWV"
      },
      "source": [
        "#inputs = torch.load(f\"{drive_path}/imc-prediction/tensors/inputs.pt\")\n",
        "inputs_with_dna = torch.load(f\"{drive_path}/imc-prediction/tensors/inputs_with_dna.pt\")\n",
        "alpha_collagen_keratin_targets = torch.load(f\"{drive_path}/imc-prediction/tensors/alpha_collagen_keratin_targets.pt\")\n",
        "#collagen_targets = torch.load(f\"{drive_path}/imc-prediction/tensors/collagen_targets.pt\")\n",
        "#dna_targets = torch.load(f\"{drive_path}/imc-prediction/tensors/dna_targets.pt\")\n",
        "#inputs_with_dna = torch.cat([inputs, dna_targets], dim=1)"
      ],
      "id": "kfZH1qdT2bWV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqLvG-hA5tSs"
      },
      "source": [
        "all_indices = range(inputs_with_dna.shape[0])\n",
        "random.seed(123)\n",
        "val_indices = random.sample(all_indices, math.floor(inputs_with_dna.shape[0] / 4))\n",
        "train_indices = list(set(all_indices) - set(val_indices))\n",
        "train_inputs = inputs_with_dna.index_select(dim=0, index=torch.tensor(train_indices))\n",
        "train_targets = alpha_collagen_keratin_targets.index_select(dim=0, index=torch.tensor(train_indices))\n",
        "val_inputs = inputs_with_dna.index_select(dim=0, index=torch.tensor(val_indices))\n",
        "val_targets = alpha_collagen_keratin_targets.index_select(dim=0, index=torch.tensor(val_indices))"
      ],
      "id": "AqLvG-hA5tSs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVkU0SIoT5we"
      },
      "source": [
        "t1 = transforms.Compose([\n",
        "    transforms.RandomRotation([90, 90], expand=True),\n",
        "    transforms.RandomResizedCrop([271, 304], scale=[1, 1]),  # reflect-pad instead of resizing?\n",
        "])\n",
        "#t2 = transforms.RandomRotation([180, 180])\n",
        "#t3 = transforms.Compose([\n",
        "#    transforms.RandomRotation([270, 270], expand=True),\n",
        "#    transforms.RandomResizedCrop([271, 304], scale=[1, 1]),  # reflect-pad instead of resizing?\n",
        "#])\n",
        "t4 = transforms.RandomHorizontalFlip(p=1)\n",
        "#t5 = transforms.RandomVerticalFlip(p=1)"
      ],
      "id": "MVkU0SIoT5we",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXb6ZSSrZZmW"
      },
      "source": [
        "#normalize_transform = transforms.Normalize(\n",
        "#    mean=[0.45, 0.45],\n",
        "#    std=[0.225, 0.225],\n",
        "#)\n",
        "#train_inputs_augmented = torch.cat([\n",
        "#    normalize_transform(train_inputs),\n",
        "#    transforms.Compose([t1, normalize_transform])(train_inputs),\n",
        "#    transforms.Compose([t2, normalize_transform])(train_inputs),\n",
        "#    transforms.Compose([t3, normalize_transform])(train_inputs),\n",
        "#    transforms.Compose([t4, normalize_transform])(train_inputs),\n",
        "#    transforms.Compose([t5, normalize_transform])(train_inputs),\n",
        "#])\n",
        "train_inputs_augmented = torch.cat([\n",
        "    train_inputs,\n",
        "    t1(train_inputs),\n",
        "    #t2(train_inputs),\n",
        "    #t3(train_inputs),\n",
        "    t4(train_inputs),\n",
        "    #t5(train_inputs),\n",
        "])\n",
        "train_targets_augmented = torch.cat([\n",
        "    train_targets,\n",
        "    t1(train_targets),\n",
        "    #t2(train_targets),\n",
        "    #t3(train_targets),\n",
        "    t4(train_targets),\n",
        "    #t5(train_targets),\n",
        "])"
      ],
      "id": "EXb6ZSSrZZmW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hi6C4q69CzG"
      },
      "source": [
        "inputs = None\n",
        "collagen_targets = None\n",
        "dna_targets = None\n",
        "inputs_with_dna = None\n",
        "train_inputs = None\n",
        "train_targets = None"
      ],
      "id": "0Hi6C4q69CzG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvRw2-OInC6Y"
      },
      "source": [
        "#train_dataset = TensorDataset(\n",
        "#    torch.load(f\"{drive_path}/imc-prediction/tensors/train_inputs.pt\"),\n",
        "#    torch.load(f\"{drive_path}/imc-prediction/tensors/train_targets.pt\"),\n",
        "#)\n",
        "#val_dataset = TensorDataset(\n",
        "#    torch.load(f\"{drive_path}/imc-prediction/tensors/val_inputs.pt\"),\n",
        "#    torch.load(f\"{drive_path}/imc-prediction/tensors/val_targets.pt\"),\n",
        "#)"
      ],
      "id": "hvRw2-OInC6Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "realistic-trail"
      },
      "source": [
        "#batch_size = 1\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(\n",
        "    #dataset=train_dataset,\n",
        "    #dataset=TensorDataset(train_inputs, train_targets),\n",
        "    dataset=TensorDataset(train_inputs_augmented, train_targets_augmented),\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4,\n",
        "    shuffle=True,\n",
        "    #pin_memory=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    #dataset=val_dataset,\n",
        "    dataset=TensorDataset(val_inputs, val_targets),\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4,\n",
        "    shuffle=False,\n",
        "    #pin_memory=True,\n",
        ")"
      ],
      "id": "realistic-trail",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMUyoXKw10Wp"
      },
      "source": [
        "train_inputs_augmented = None\n",
        "train_targets_augmented = None\n",
        "val_inputs = None\n",
        "val_targets = None"
      ],
      "id": "BMUyoXKw10Wp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fatal-findings",
        "outputId": "c98de860-f7f9-424c-b25e-d73dfdc217d9"
      },
      "source": [
        "pl.seed_everything(55)\n",
        "\n",
        "model = MyUNet(\n",
        "    batch_size=batch_size,\n",
        "    #num_layers=5,\n",
        "    input_channels=2,\n",
        "    dropout=0.42,\n",
        "    #weight_decay=1e-4,\n",
        "    #learning_rate=1e-3,\n",
        "    #protein_multiplier=16,\n",
        "    #protein_multiplier_index=0,\n",
        "    #protein_multiplier=8,\n",
        "    #protein_multiplier_index=collagen_index,\n",
        "    architecture=\"smp.UnetPlusPlus\",\n",
        "    #architecture=\"smp.MAnet\",\n",
        "    encoder_depth=4,\n",
        "    decoder_channels=(256, 128, 64, 32),\n",
        "    #encoder_depth=3,\n",
        "    #decoder_channels=(128, 64, 32),\n",
        "    decoder_use_batchnorm=True,\n",
        ")"
      ],
      "id": "fatal-findings",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 55\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "literary-reputation",
        "outputId": "347a31ae-0891-4492-e171-916bbf17eec6"
      },
      "source": [
        "logger = WandbLogger(\n",
        "  name=f\"{datetime.now()}\"[:19],\n",
        "  project=\"unet1\",\n",
        ")\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=500,\n",
        "    logger=logger,\n",
        "    callbacks=[\n",
        "        LoggingCallback(),\n",
        "        EarlyStopping(\n",
        "            #monitor=\"val_loss_multiplied\",\n",
        "            monitor=\"val_loss\",\n",
        "            patience=25,\n",
        "        ),\n",
        "    ],\n",
        "    #accumulate_grad_batches=10,\n",
        "    stochastic_weight_avg=True,\n",
        "    check_val_every_n_epoch=1,\n",
        "    gpus=1,\n",
        "    #resume_from_checkpoint=\"./epoch_50.ckpt\",\n",
        ")"
      ],
      "id": "literary-reputation",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "Both every_n_train_steps and every_n_val_epochs are not set. Setting every_n_val_epochs=1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "interim-migration"
      },
      "source": [
        "trainer.fit(model, train_loader, val_loader)"
      ],
      "id": "interim-migration",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCM3DBfFgnES"
      },
      "source": [
        "# higher learning rate\n",
        "# MSE and other losses (hybrid MSE / cross entropy?)\n",
        "# L1 loss? L1 \"reconstruction\" loss? pix2pix paper says it's better than GAN for sem seg\n",
        "# GAN conditional on input channels!\n",
        "# ^ look for GANs conditional on images online - is this how style transfer works? StyleGAN\n",
        "# use tanh and make everything (-1, 1)? see how you did this in the homework\n",
        "#   other sebastian suggestions\n",
        "# ask jin sun / sebastian / etc what evaluation metrics would be good\n",
        "#  per pixel classification isn't great because of intensities\n",
        "#  have pathologists rate? how exactly?"
      ],
      "id": "FCM3DBfFgnES",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KeYijnP1z9H"
      },
      "source": [
        "# print out weight matrices, see if weights are mostly 0. but is that dead relu, not vanishing gradient?\n",
        "# wouldn't vanishing gradient be if change to weights is mostly 0?"
      ],
      "id": "_KeYijnP1z9H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sCw9VmlaC0R"
      },
      "source": [
        "# make dataset with 4 channels + data augmentation (or augment at runtime)\n",
        "#     should fit in memory\n",
        "#     train with holdout in same patients\n",
        "# get new models really overfitting:\n",
        "#     log better training examples - pull consistent indices directly from dataset and run .cuda()/.cpu() etc?\n",
        "#     more encoder/decoder channels?\n",
        "#     switch back to one protein (also try 2-4, think about which would be good)\n",
        "#     look through wandb logs for best overfitting\n",
        "# pathology checkpoints\n",
        "#    or pathology datasets to fine tune smp models\n",
        "# look at a variety of proteins. maybe certain ones it does much better than others?"
      ],
      "id": "7sCw9VmlaC0R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaqXzpuikRLC"
      },
      "source": [
        "# train within patients - then you don't have issue of different disease, etc\n",
        "# train on large greyscale pathology dataset with self supervision fill in the blank etc\n",
        "# try coordconv\n",
        "# test late 2cnm83td models against training data to assess overfitting - wandb didn't get informative examples"
      ],
      "id": "UaqXzpuikRLC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-itpjSKdFzrm"
      },
      "source": [
        "wandb.finish()"
      ],
      "id": "-itpjSKdFzrm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZWRt3iFrxwl"
      },
      "source": [],
      "id": "AZWRt3iFrxwl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9VlrZPutjs-"
      },
      "source": [],
      "id": "I9VlrZPutjs-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz7ezS8-fYbr"
      },
      "source": [
        "def get_val_preds(model, protein_channel):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        #fig, axs = plt.subplots(len(val_dataset), 3, figsize=(3 * 2, len(val_dataset) * 2))\n",
        "        fig, axs = plt.subplots(5, 3, figsize=(3 * 2, 5 * 2))\n",
        "        i = 0\n",
        "        for xs, ys in val_loader:\n",
        "            if i == 5:\n",
        "                break\n",
        "            n = xs.shape[0]\n",
        "            preds = model(xs)\n",
        "            for _i in range(n):\n",
        "                _axs = axs[i + _i]\n",
        "                _axs[0].imshow(xs[_i][0].cpu().detach().numpy())\n",
        "                _axs[1].imshow(preds[_i][protein_channel].cpu().detach().numpy())\n",
        "                _axs[2].imshow(ys[_i][protein_channel].cpu().detach().numpy())\n",
        "                for j in range(3):\n",
        "                    _axs[j].set_xticks([])\n",
        "                    _axs[j].set_yticks([])\n",
        "            i += n\n",
        "        fig.tight_layout()"
      ],
      "id": "Pz7ezS8-fYbr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ktN30weTe1G",
        "outputId": "52c6c4bc-a928-42e0-8265-b3a7ffda6bdc"
      },
      "source": [
        "!wandb login"
      ],
      "id": "5ktN30weTe1G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbzrry\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoltLcyBCrSY",
        "outputId": "5a567e53-98ad-4a07-ea9c-83127c01c48a"
      },
      "source": [
        "wandb.restore(\"epoch_39.ckpt\", run_path=\"bzrry/unet1/2cnm83td\")\n",
        "wandb.restore(\"epoch_59.ckpt\", run_path=\"bzrry/unet1/2cnm83td\")\n",
        "wandb.restore(\"epoch_79.ckpt\", run_path=\"bzrry/unet1/3b1u16fg\")"
      ],
      "id": "HoltLcyBCrSY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='/content/epoch_79.ckpt' mode='r' encoding='UTF-8'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA4va1sg_Pbd"
      },
      "source": [
        "model_2cnm83td_39 = MyUNet.load_from_checkpoint(f\"./epoch_39.ckpt\").cuda()\n",
        "model_2cnm83td_59 = MyUNet.load_from_checkpoint(f\"./epoch_59.ckpt\").cuda()\n",
        "#model_3b1u16fg_79 = MyUNet.load_from_checkpoint(f\"./epoch_79.ckpt\").cuda()"
      ],
      "id": "TA4va1sg_Pbd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lUcsteSX19R"
      },
      "source": [
        "get_val_preds(model_2cnm83td_39, collagen_index)"
      ],
      "id": "4lUcsteSX19R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp5Px9sOf1V7"
      },
      "source": [
        "get_val_preds(model_2cnm83td_39, 0)"
      ],
      "id": "Cp5Px9sOf1V7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bf2jsx5gS4J"
      },
      "source": [
        "get_val_preds(model_2cnm83td_59, collagen_index)"
      ],
      "id": "2Bf2jsx5gS4J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "majMmR7KiF8a"
      },
      "source": [
        "get_val_preds(model_2cnm83td_59, 0)"
      ],
      "id": "majMmR7KiF8a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ3Vq99DM852"
      },
      "source": [],
      "id": "nZ3Vq99DM852",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN2fEtBpqxi2",
        "outputId": "3ed9f7cb-4f91-44d3-dfce-d1365a4fa0ff"
      },
      "source": [
        "!nvidia-smi --query-gpu=utilization.gpu,utilization.memory,memory.total,memory.free,memory.used --format=csv -l 5\n",
        "#!nvidia-smi\n",
        "#!nvidia-smi --gpu-reset -i 0"
      ],
      "id": "dN2fEtBpqxi2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "utilization.gpu [%], utilization.memory [%], memory.total [MiB], memory.free [MiB], memory.used [MiB]\n",
            "0 %, 0 %, 16280 MiB, 65 MiB, 16215 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuV2hg_oGT6v"
      },
      "source": [
        "# might need a bigger model / more layers/params/etc to handle more training examples?\n",
        "# get to overfitting\n",
        "# make sure model is actually training against all the examples...seems like it's going fast?\n",
        "# layer/instance norm instead of batch norm?"
      ],
      "id": "DuV2hg_oGT6v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6duoRFAvWdr"
      },
      "source": [
        "wandb.init()"
      ],
      "id": "S6duoRFAvWdr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-weU_ww9kf9"
      },
      "source": [
        "class FullyConv(nn.Module):\n",
        "    def __init__(self, num_features, kernel_size, stride, padding):\n",
        "        super(FullyConv, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1, num_features, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Conv2d(num_features, num_features, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Conv2d(num_features, num_features, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Conv2d(num_features, 1, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "id": "e-weU_ww9kf9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Yv7ZhykUNJ"
      },
      "source": [],
      "id": "Q7Yv7ZhykUNJ",
      "execution_count": null,
      "outputs": []
    }
  ]
}